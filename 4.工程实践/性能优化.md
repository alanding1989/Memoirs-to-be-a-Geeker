
<!-- vim-markdown-toc GFM -->

- [常用的性能优化方法](#常用的性能优化方法)
  - [按照以下步骤优化:](#按照以下步骤优化)

<!-- vim-markdown-toc -->


### 常用的性能优化方法
> 以下次序最好不要变，越往下时间越长，收益越低。

1. 垂直扩展： 考虑平台执行环境与使用模式是否匹配。
2. 垂直扩展： 考虑程序优化，数据类型的使用。  
3. 垂直扩展： 考虑优化算法，降低复杂度。  
4. 垂直扩展： 考虑缓存，异步。分析CPU，内存，网络使用情况。考虑升级机器，多搞点内存。  
5. 水平扩展： 考虑集群，并行计算，找个hadoop集群，写成mapreduce放在hadoop上跑。  
6. 垂直扩展： 考虑拿C或C++重写。  



#### 按照以下步骤优化:  

1. 首先，确保真的需要把全部数据过一遍，如果可以通过一些糙快猛方式过滤掉无用数据最好。  
（比如有些明显无用的东西可以直接通过grep过滤掉，grep这种程序写的一般比你写的python程序要快好多好多)。  

2. top看CPU跑满了没。单线程单进程实现能不能搞成多进程的，要充分利用CPU。  
   然后top看每个核都跑满了没。没跑满是因为IO吗。是的话IO能搞成异步的么。或IO次数太多，能不能减少IO次数。  
   甚至只搞一次IO，比如1G的东西，能不能一次全搞到内存里，然后所有东西在内存里处理（这样的话貌似写成C的
   更方便一点）。  

3. 如果每个核心都跑满了，那就看计算都花在什么地方。可以用profile, hotshot等工具测一下。  
   粗略比较一下在1/16 数据、1/8数据、1/4数据、1/2数据的情况下hotshot的结果，看函数花的时间是怎么涨的。  
   找出花时间最多的一个或几个东西（所谓瓶颈），有针对性优化。  

4. 找到问题所在之后，寻求解决方案。  
   - 如果是python带的数据结构不合适，能不能用numpy之类的东西解决，能不能用一些数据库解决。  
   - 比如需要多个进程一起往一个大字典里写，可以考虑全往一个redis里写，任务队列，内存缓冲，函数缓存。  
   - 如果是算法不够好，能不能优化算法。   
   - 能不能有的地方用cython包装一个C实现。  
   - 试试一些奇怪的东西，比如PyPy。  

5. Python工具： 先用cProfile宏观分析找到需要分析的函数，再用line_profiler/kernprof微观逐行分析。
   - cProfile        : C语言实现的性能测试模块，接口和profile一样。
   - line_profiler   : 可以统计每行代码的执行次数和执行时间等，时间单位为微妙。
   - memory_profiler : 可以统计每行代码占用的内存大小。
   - objgraph        : 可以创建内存中存在的对象图表，用于定位内存泄露。
   - pycharm  


